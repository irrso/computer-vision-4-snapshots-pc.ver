# 📷 MediaPipe와 PyQt를 이용한 인생 네컷 pc 프로그램

<div align="right">
  컴퓨터비전
  🗓️ 2023.05.26 - 2023.06.11
</div>
<br>

<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/aa89991a-cd4f-4fc5-aadf-59d1aea5cbed">
<br><br>

## 메인 아이디어
- 인생 네컷을 컴퓨터로 간편하게 촬영할 수 없을까❓
- 사람을 인식해서 여러가지 얼굴 필터 기능을 추가해보자 💡
- MediaPipe를 이용해 인생 네컷 프로그램 제작 💻
<br>

## 사용자 인터페이스
<!--메인화면-->
<h3 align="center">
  프로그램을 실행하면 시작 또는 나가기 버튼을 누를 수 있어요! ⭐
</h3>
<div align="center">
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/21119323-3367-4d59-8dbb-bb420df72c3e"/>
</div>
<hr>

<!--시작-->
<h3 align="center">
  시작 버튼을 눌러 캠을 실행시켜봐요! 📹
</h3>
<div align="center">

  **웹캠 영상이 화면에 나타나고 촬영 버튼과 필터 버튼이 활성화돼요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/5c00a0ec-f410-4356-95c7-3e2ebe42a1e7"/>
</div>
<hr>

<!--필터-->
<h3 align="center">
  필터 버튼을 눌러 얼굴을 확인해봐요! 🫥
</h3>
<div align="center">
  
   **하나의 필터를 적용할 수 있어요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/339edec5-eadb-4ba3-990b-3602542c721f"/>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/06275901-0bd6-4cb3-ac25-5f8c40a9c2f4"/>
  <br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/9cfd29ae-6086-4147-b05d-6ae03e2f4f6e"/>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/e3f10b83-a288-4f3f-82ff-b917191261b4"/>
  <br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/72953b69-cdd5-49af-b478-60d914041065"/>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/97fa97f4-75fb-4fed-8fe3-7dfe828331f0"/>
  <br><br>
  순서대로 코에 걸친 선글라스, 볼터치, 볼하트, 머리 위 구름, 맥하트 필터가 적용돼요. <br>
  필터를 적용하고 싶지 않다면 필터x를 누르면 돼요.
</div>
<hr>

<!--여러명-->
<h3 align="center">
  여러 사람들과 다같이 찍어봐요! 👨🏻‍👩🏻‍👧🏻‍👦🏻
</h3>
<div align="center">

   **필터 적용은 최대 4명까지 가능해요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/fb66d0a2-acce-4b65-8e94-bf179950a48f"/>
</div>
<hr>

<!--촬영-->
<h3 align="center">
  촬영 버튼을 눌러 본격적으로 사진을 찍어봐요! 📷
</h3>
<div align="center">
  
   **영상이 캡쳐되며 웹캠 왼쪽 하단 옆에서 찍은 횟수를 확인할 수 있어요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/bbfe0083-af29-432a-870e-735212ca3552"/>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/357e14b8-e9bc-4ddf-9ec3-d8cc3b057db6"/>
  <br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/2d13939c-7e04-450e-8946-4cddfd1d6e7e"/>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/b1387ea8-8a70-490f-90b6-162806d66c8f"/>
</div>
<hr>

<!--촬영완료-->
<h3 align="center">
  4번 촬영을 완료하고 나온 사진을 확인해요! 🥰
</h3>
<div align="center">
  
   **다시 찍고 싶다면 재촬영을, 마음에 들면 저장 버튼을 눌러줘요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/5dc3e0ba-bd73-4146-ba25-ec71c66e446d"/>
</div>
<hr>

<!--저장-->
<h3 align="center">
  저장 버튼을 눌러 원하는 위치에 사진을 저장해요! ✅
</h3>
<div align="center">
  
   **파일 이름을 작성하고 jpeg 형식으로 저장해요 🤍** <br><br>
  <img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/0d502cfd-f212-41c1-ada2-8919848e8954"/>
</div>
<br>

## 기술 스택
|분류|기술 스택|
|:--:|--|
|front|<img src="https://img.shields.io/badge/PyQt-41CD52.svg?style=flat-square&logo=Qt&logoColor=white"/> <img src="https://img.shields.io/badge/Python-3776AB.svg?style=flat-square&logo=python&logoColor=white"/>|
|back|<img src="https://img.shields.io/badge/MediaPipe-20A6C9.svg?style=flat-square&logo=&logoColor=white"/> <img src="https://img.shields.io/badge/OpenCV-5C3EE8.svg?style=flat-square&logo=opencv&logoColor=white"/> <img src="https://img.shields.io/badge/Python-3776AB.svg?style=flat-square&logo=python&logoColor=white"/>|
<br>

## 시스템 기능
### 프로그램 실행
- `QPushButton`으로 시작, 촬영, 재촬영, 저장, 나가기 버튼 생성
- `QRadioButton`으로 필터1, 필터2, 필터3, 필터4, 필터5, 필터x 버튼 생성
- `QLabel`로 촬영 횟수 레이블 생성 후 `setVisible(False)`로 설정
- `QLabel`로 웹캠 영상 레이블 생성
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/21119323-3367-4d59-8dbb-bb420df72c3e" width="35%"/>

<details>
    <summary> <img src="https://img.shields.io/badge/__init__-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def __init__(self):
      super().__init__()
      
      self.setWindowTitle('인생네컷 PC.ver')
      self.setGeometry(200, 200, 880, 500)
      
      self.startBtn = QPushButton('시작', self)
      self.startBtn.setGeometry(10, 10, 100, 30)
      self.startBtn.clicked.connect(self.startFunction)
      
      self.photoBtn = QPushButton('촬영', self)
      self.photoBtn.setGeometry(10, 45, 100, 30)
      self.photoBtn.clicked.connect(self.photoFunction)
      self.photoBtn.setEnabled(False)
      
      self.rephotoBtn = QPushButton('재촬영', self)
      self.rephotoBtn.setGeometry(10, 80, 100, 30)
      self.rephotoBtn.clicked.connect(self.rephotoFunction)
      self.rephotoBtn.setEnabled(False)
      
      self.saveBtn = QPushButton('저장', self)
      self.saveBtn.setGeometry(10, 115, 100, 30)
      self.saveBtn.clicked.connect(self.savcloseFunction)
      self.saveBtn.setEnabled(False)
      
      self.closeBtn = QPushButton('나가기', self)
      self.closeBtn.setGeometry(10, 150, 100, 30)
      self.closeBtn.clicked.connect(self.closeFunction)
      
      self.filter1 = QRadioButton('필터1', self)
      self.filter1.setGeometry(130, 10, 100, 30)
      self.filter1.clicked.connect(self.sunglassFunction)
      self.filter1.setEnabled(False)
      
      self.filter2 = QRadioButton('필터2', self)
      self.filter2.setGeometry(130, 40, 100, 30)
      self.filter2.clicked.connect(self.blushFunction)
      self.filter2.setEnabled(False)
      
      self.filter3 = QRadioButton('필터3', self)
      self.filter3.setGeometry(130, 70, 100, 30)
      self.filter3.clicked.connect(self.heartFunction)
      self.filter3.setEnabled(False)
      
      self.filter4 = QRadioButton('필터4', self)
      self.filter4.setGeometry(130, 100, 100, 30)
      self.filter4.clicked.connect(self.cloudFunction)
      self.filter4.setEnabled(False)
      
      self.filter5 = QRadioButton('필터5', self)
      self.filter5.setGeometry(130, 130, 100, 30)
      self.filter5.clicked.connect(self.macheartFunction)
      self.filter5.setEnabled(False)
      
      self.nofilter = QRadioButton('필터x', self)
      self.nofilter.setGeometry(130, 160, 100, 30)
      self.nofilter.clicked.connect(self.nofilterFunction)
      self.nofilter.setEnabled(False)
      
      self.label = QLabel('0/4', self)
      self.label.setGeometry(150, 450, 100, 30)
      self.label.setAlignment(Qt.AlignCenter)
      self.label.setVisible(False)
      
      self.img_label = QLabel('', self)
      self.img_label.setGeometry(230, 10, 640, 480)
  ```
</details>

### 시작 기능
- 시작 버튼 클릭 시 `startFuction()` 함수 호출
- `cap`과 `mesh` 변수 초기화 후 `startVideo()` 함수 호출
- `showVideo()` 함수 호출하여 `img_lable`에 웹캠 영상 표시
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/5c00a0ec-f410-4356-95c7-3e2ebe42a1e7" width="35%"/>

<details>
    <summary> <img src="https://img.shields.io/badge/startFuction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def startFunction(self):
      #시작
      self.startBtn.setEnabled(False)
      self.photoBtn.setEnabled(True)
      self.filter1.setEnabled(True)
      self.filter2.setEnabled(True)
      self.filter3.setEnabled(True)
      self.filter4.setEnabled(True)
      self.filter5.setEnabled(True)
      self.nofilter.setEnabled(True)
      self.label.setVisible(True)
      
      global cap
      cap = cv.VideoCapture(0, cv.CAP_DSHOW)
      self.imgs=[]
      
      global mesh
      mp_mesh = mp.solutions.face_mesh 
      mesh = mp_mesh.FaceMesh(max_num_faces=4, refine_landmarks=True, min_detection_confidence=0.5,
                              min_tracking_confidence=0.5)
      
      self.startVideo()

  def startVideo(self):
      while True:
          ret, self.frame = cap.read()
          if not ret:
              print('프레임 획득 실패')
              break
          
          self.showVideo()
            
  def showVideo(self):
      img = cv.cvtColor(cv.flip(self.frame, 1), cv.COLOR_BGR2RGB)
      img = QImage(img.data, self.frame.shape[1], self.frame.shape[0], self.frame.shape[1]*self.frame.shape[2],
                   QImage.Format_RGB888)
      pixmap = QPixmap.fromImage(img)
      self.img_label.setPixmap(pixmap)
      
      cv.waitKey(1)
  ```
</details>


### 선글라스 필터
- `sunglass` 변수를 `sunglass.png`로 초기화
- `process`를 통해 얼굴 객체 검출
- `landmark`에서 양쪽 눈의 시작점, 끝점, 중앙 랜드마크 좌표 가져옴
- 얼굴 크기를 계산하고 필터 크기를 적절히 조절하여 프레임에 적용
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/339edec5-eadb-4ba3-990b-3602542c721f"/>

<details>
    <summary> <img src="https://img.shields.io/badge/sunglassFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def sunglassFunction(self, state):
      # 선글라스 필터
      while True:
          ret, self.frame = cap.read()
          
          sunglass = cv.imread('sunglass.png', cv.IMREAD_UNCHANGED)
  
          res = mesh.process(cv.cvtColor(self.frame, cv.COLOR_BGR2RGB))

          if res.multi_face_landmarks:
              for landmarks in res.multi_face_landmarks:
                  eye_lx, eye_ly = 0, 0
                  eye_rx, eye_ry = 0, 0
                  eye_cx, eye_cy = 0, 0
                  
                  for id, p in enumerate(landmarks.landmark):
                      x, y = int(p.x*self.frame.shape[1]), int(p.y*self.frame.shape[0])
                      if id == 446:
                         eye_lx, eye_ly = x, y
                      if id == 226:
                          eye_rx, eye_ry = x, y
                      if id == 6:
                         eye_cx, eye_cy = x, y
                             
                  eye_w = eye_lx-eye_rx
                  eye_h = int(eye_w/1.8)
                      
                  x1, x2 = int(eye_cx - eye_w), int(eye_cx + eye_w)
                  y1, y2 = int(eye_cy - 1.25*eye_h/2), int(eye_cy + 2.75*eye_h/2)
                  
                  if eye_w > 0 and eye_h > 0 and x1 > 0 and y1 > 0 and x2 < self.frame.shape[1] and y2 < self.frame.shape[0]:
                      sunglasses = cv.resize(sunglass, dsize=(2*eye_w, 2*eye_h))
                      alpha = sunglasses[:, :, 3:]/255
                      self.frame[y1:y2, x1:x2] = self.frame[y1:y2, x1:x2]*(1-alpha) + sunglasses[:, :, :3]*alpha
                  
              
          self.showVideo()
  ```
</details>

### 볼터치 필터
- `blush` 변수를 `blush.png`로 초기화
- `process`를 통해 얼굴 객체 검출
- `landmark`에서 양쪽 볼의 왼쪽끝, 오른쪽끝, 중앙 랜드마크 좌표 가져옴
- 얼굴 크기를 계산하고 필터 크기를 적절히 조절하여 프레임에 적용
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/06275901-0bd6-4cb3-ac25-5f8c40a9c2f4"/>

<details>
    <summary> <img src="https://img.shields.io/badge/blushFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
   def blushFunction(self, state):
       # 볼터치 필터
       while True:
           ret, self.frame = cap.read()
           
           blush = cv.imread('blush.png', cv.IMREAD_UNCHANGED)
           
           res = mesh.process(cv.cvtColor(self.frame, cv.COLOR_BGR2RGB))
   
           if res.multi_face_landmarks:
               for landmarks in res.multi_face_landmarks:
                   lcheek_lx, lcheek_ly = 0, 0
                   lcheek_rx, lcheek_ry = 0, 0
                   lcheek_cx, lcheek_cy = 0, 0
                   
                   rcheek_lx, rcheek_ly = 0, 0
                   rcheek_rx, rcheek_ry = 0, 0
                   rcheek_cx, rcheek_cy = 0, 0
                   
                   for id, p in enumerate(landmarks.landmark):
                       x, y = int(p.x*self.frame.shape[1]), int(p.y*self.frame.shape[0])
                       if id == 366:
                           lcheek_lx, lcheek_ly = x, y
                       if id == 358:
                           lcheek_rx, lcheek_ry = x, y
                       if id == 280:
                           lcheek_cx, lcheek_cy = x, y
                       if id == 129:
                           rcheek_lx, rcheek_ly = x, y
                       if id == 137:
                           rcheek_rx, rcheek_ry = x, y
                       if id == 50:
                           rcheek_cx, rcheek_cy = x, y
                           
                   lcheek_w, rcheek_w = lcheek_lx-lcheek_rx, rcheek_lx-rcheek_rx
                   lcheek_h, rcheek_h = lcheek_w, rcheek_w
                       
                   x1, x2 = int(lcheek_cx - lcheek_w), int(lcheek_cx + lcheek_w)
                   y1, y2 = int(lcheek_cy - lcheek_h), int(lcheek_cy + lcheek_h)
                   
                   if lcheek_w > 0 and lcheek_h > 0 and x1 > 0 and y1 > 0 and x2 < self.frame.shape[1] and y2 < self.frame.shape[0]:
                       lblush = cv.resize(blush, dsize=(2*lcheek_w, 2*lcheek_h))
                       alpha = lblush[:, :, 3:]/255
                       self.frame[y1:y2, x1:x2] = self.frame[y1:y2, x1:x2]*(1-alpha) + lblush[:, :, :3]*alpha
                       
                   x3, x4 = int(rcheek_cx - rcheek_w), int(rcheek_cx + rcheek_w)
                   y3, y4 = int(rcheek_cy - rcheek_h), int(rcheek_cy + rcheek_h)
                   
                   if rcheek_w > 0 and rcheek_h > 0 and x3 > 0 and y3 > 0 and x4 < self.frame.shape[1] and y4 < self.frame.shape[0]:
                       rblush = cv.resize(blush, dsize=(2*rcheek_w, 2*rcheek_h))
                       alpha = rblush[:, :, 3:]/255
                       self.frame[y3:y4, x3:x4] = self.frame[y3:y4, x3:x4]*(1-alpha) + rblush[:, :, :3]*alpha
               
           self.showVideo()
  ```
</details>

### 볼하트 필터
- `heart` 변수를 `heart.png`로 초기화
- `process`를 통해 얼굴 객체 검출
- `landmark`에서 양쪽 볼의 왼쪽끝, 오른쪽끝, 중앙 랜드마크 좌표 가져옴
- 얼굴 크기를 계산하고 필터 크기를 적절히 조절하여 프레임에 적용
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/9cfd29ae-6086-4147-b05d-6ae03e2f4f6e"/>

<details>
    <summary> <img src="https://img.shields.io/badge/heartFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def heartFunction(self, state):
      # 볼하트 필터
      while True:
          ret, self.frame = cap.read()
          
          heart = cv.imread('heart.png', cv.IMREAD_UNCHANGED)
          
          res = mesh.process(cv.cvtColor(self.frame, cv.COLOR_BGR2RGB))
  
          if res.multi_face_landmarks:
              for landmarks in res.multi_face_landmarks:
                  lcheek_lx, lcheek_ly = 0, 0
                  lcheek_rx, lcheek_ry = 0, 0
                  lcheek_cx, lcheek_cy = 0, 0
                  
                  rcheek_lx, rcheek_ly = 0, 0
                  rcheek_rx, rcheek_ry = 0, 0
                  rcheek_cx, rcheek_cy = 0, 0
                  
                  for id, p in enumerate(landmarks.landmark):
                      x, y = int(p.x*self.frame.shape[1]), int(p.y*self.frame.shape[0])
                      if id == 366:
                          lcheek_lx, lcheek_ly = x, y
                      if id == 358:
                          lcheek_rx, lcheek_ry = x, y
                      if id == 280:
                          lcheek_cx, lcheek_cy = x, y
                      if id == 129:
                          rcheek_lx, rcheek_ly = x, y
                      if id == 137:
                          rcheek_rx, rcheek_ry = x, y
                      if id == 50:
                          rcheek_cx, rcheek_cy = x, y
                          
                  lcheek_w, rcheek_w = lcheek_lx-lcheek_rx, rcheek_lx-rcheek_rx
                  lcheek_h, rcheek_h = lcheek_w, rcheek_w
                      
                  x1, x2 = int(lcheek_cx - lcheek_w/2), int(lcheek_cx + lcheek_w/2)
                  y1, y2 = int(lcheek_cy - lcheek_h/2), int(lcheek_cy + lcheek_h/2)
                  
                  if lcheek_w > 0 and lcheek_h > 0 and x1 > 0 and y1 > 0 and x2 < self.frame.shape[1] and y2 < self.frame.shape[0]:
                      lheart = cv.resize(heart, dsize=(lcheek_w, lcheek_h))
                      alpha = lheart[:, :, 3:]/255
                      self.frame[y1:y2, x1:x2] = self.frame[y1:y2, x1:x2]*(1-alpha) + lheart[:, :, :3]*alpha
                      
                  x3, x4 = int(rcheek_cx - rcheek_w/2), int(rcheek_cx + rcheek_w/2)
                  y3, y4 = int(rcheek_cy - rcheek_h/2), int(rcheek_cy + rcheek_h/2)
                  
                  if rcheek_w > 0 and rcheek_h > 0 and x3 > 0 and y3 > 0 and x4 < self.frame.shape[1] and y4 < self.frame.shape[0]:
                      rheart = cv.resize(heart, dsize=(rcheek_w, rcheek_h))
                      alpha = rheart[:, :, 3:]/255
                      self.frame[y3:y4, x3:x4] = self.frame[y3:y4, x3:x4]*(1-alpha) + rheart[:, :, :3]*alpha
              
          self.showVideo()
  ```
</details>

### 구름 필터
- `cloud` 변수를 `cloud.png`로 초기화
- `process`를 통해 얼굴 객체 검출
- `landmark`에서 머리의 왼쪽끝, 오른쪽끝, 중앙 랜드마크 좌표 가져옴
- 얼굴 크기를 계산하고 필터 크기를 적절히 조절하여 프레임에 적용
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/e3f10b83-a288-4f3f-82ff-b917191261b4"/>

<details>
    <summary> <img src="https://img.shields.io/badge/cloudFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def cloudFunction(self, state):
      # 구름 필터
      while True:
          ret, self.frame = cap.read()
          
          cloud = cv.imread('cloud.png', cv.IMREAD_UNCHANGED)
          
          res = mesh.process(cv.cvtColor(self.frame, cv.COLOR_BGR2RGB))
  
          if res.multi_face_landmarks:
              for landmarks in res.multi_face_landmarks:
                  head_x, head_y = 0, 0
                  
                  for id, p in enumerate(landmarks.landmark):
                      x, y = int(p.x*self.frame.shape[1]), int(p.y*self.frame.shape[0])
                      if id == 67:
                          head_lx, head_ly = x, y
                      if id == 287:
                          head_rx, head_ry = x, y
                      if id == 10:
                          head_cx, head_cy = x, y
                             
                  head_w = head_rx-head_lx
                  head_h = int(head_w/1.54)
                  
                  x1, x2 = int(head_cx - 3*head_w/2), int(head_cx + 3*head_w/2)
                  y1, y2 = int(head_cy - 7*head_h/2), int(head_cy - head_h/2)
                  
                  if head_w > 0 and head_h > 0 and x1 > 0 and y1 > 0 and x2 < self.frame.shape[1] and y2 < self.frame.shape[0]:
                      clouds = cv.resize(cloud, dsize=(3*head_w, 3*head_h)) 
                      alpha = clouds[:, :, 3:]/255
                      self.frame[y1:y2, x1:x2] = self.frame[y1:y2, x1:x2]*(1-alpha) + clouds[:, :, :3]*alpha
              
          self.showVideo()
  ```
</details>

### 맥하트 필터
- `heart` 변수를 `mac_heart.png`로 초기화
- `process`를 통해 얼굴 객체 검출
- `landmark`에서 머리의 왼쪽끝, 오른쪽끝, 중앙 랜드마크 좌표 가져옴
- 얼굴 크기를 계산하고 필터 크기를 적절히 조절하여 프레임에 적용
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/72953b69-cdd5-49af-b478-60d914041065"/>

<details>
    <summary> <img src="https://img.shields.io/badge/macheartFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def heartFunction(self, state):
      # 볼하트 필터
      while True:
          ret, self.frame = cap.read()
          
          heart = cv.imread('heart.png', cv.IMREAD_UNCHANGED)
          
          res = mesh.process(cv.cvtColor(self.frame, cv.COLOR_BGR2RGB))
  
          if res.multi_face_landmarks:
              for landmarks in res.multi_face_landmarks:
                  lcheek_lx, lcheek_ly = 0, 0
                  lcheek_rx, lcheek_ry = 0, 0
                  lcheek_cx, lcheek_cy = 0, 0
                  
                  rcheek_lx, rcheek_ly = 0, 0
                  rcheek_rx, rcheek_ry = 0, 0
                  rcheek_cx, rcheek_cy = 0, 0
                  
                  for id, p in enumerate(landmarks.landmark):
                      x, y = int(p.x*self.frame.shape[1]), int(p.y*self.frame.shape[0])
                      if id == 366:
                          lcheek_lx, lcheek_ly = x, y
                      if id == 358:
                          lcheek_rx, lcheek_ry = x, y
                      if id == 280:
                          lcheek_cx, lcheek_cy = x, y
                      if id == 129:
                          rcheek_lx, rcheek_ly = x, y
                      if id == 137:
                          rcheek_rx, rcheek_ry = x, y
                      if id == 50:
                          rcheek_cx, rcheek_cy = x, y
                          
                  lcheek_w, rcheek_w = lcheek_lx-lcheek_rx, rcheek_lx-rcheek_rx
                  lcheek_h, rcheek_h = lcheek_w, rcheek_w
                      
                  x1, x2 = int(lcheek_cx - lcheek_w/2), int(lcheek_cx + lcheek_w/2)
                  y1, y2 = int(lcheek_cy - lcheek_h/2), int(lcheek_cy + lcheek_h/2)
                  
                  if lcheek_w > 0 and lcheek_h > 0 and x1 > 0 and y1 > 0 and x2 < self.frame.shape[1] and y2 < self.frame.shape[0]:
                      lheart = cv.resize(heart, dsize=(lcheek_w, lcheek_h))
                      alpha = lheart[:, :, 3:]/255
                      self.frame[y1:y2, x1:x2] = self.frame[y1:y2, x1:x2]*(1-alpha) + lheart[:, :, :3]*alpha
                      
                  x3, x4 = int(rcheek_cx - rcheek_w/2), int(rcheek_cx + rcheek_w/2)
                  y3, y4 = int(rcheek_cy - rcheek_h/2), int(rcheek_cy + rcheek_h/2)
                  
                  if rcheek_w > 0 and rcheek_h > 0 and x3 > 0 and y3 > 0 and x4 < self.frame.shape[1] and y4 < self.frame.shape[0]:
                      rheart = cv.resize(heart, dsize=(rcheek_w, rcheek_h))
                      alpha = rheart[:, :, 3:]/255
                      self.frame[y3:y4, x3:x4] = self.frame[y3:y4, x3:x4]*(1-alpha) + rheart[:, :, :3]*alpha
              
          self.showVideo()
  ```
</details>

### 촬영 기능
- 촬영 버튼 클릭 시 `photoFuction()` 함수 호출
- 버튼이 눌릴때 마다 `imgs`에 `frame` 저장
- 4번 촬영을 완료하면 `imgs`를 `np.vstack`로 수직 결합하여 새로운 윈도우 창에 표시
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/5dc3e0ba-bd73-4146-ba25-ec71c66e446d" width="45%"/>

<details>
    <summary> <img src="https://img.shields.io/badge/photoFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def photoFunction(self):
      # 촬영
      self.imgs.append(cv.flip(self.frame, 1))
      self.label.setText(str(len(self.imgs))+'/4')
      
      if len(self.imgs) > 3:
          self.photoBtn.setEnabled(False)
          self.rephotoBtn.setEnabled(True)
          self.saveBtn.setEnabled(True)
          self.saveBtn.setEnabled(True)
          
          self.stack = cv.resize(self.imgs[0], dsize=(0,0), fx=0.35, fy=0.35)
          for i in range(1, len(self.imgs)):
              self.stack = np.vstack((self.stack, cv.resize(self.imgs[i], dsize=(0,0), fx=0.35, fy=0.35)))
              
              cv.namedWindow(' ')
              cv.moveWindow(' ', 1080, 155)
              cv.imshow(' ', self.stack)
  ```
</details>

### 재촬영 기능
- 재촬영 버튼 클릭 시 `rephotoFunction()` 함수 호출
- `imgs`를 빈 배열로 초기화

<details>
    <summary> <img src="https://img.shields.io/badge/rephotoFunction-3776AB.svg?style=flat-square"/> </summary>

  ```Python
  def rephotoFunction(self):
      # 재촬영
      self.photoBtn.setEnabled(True)
      self.rephotoBtn.setEnabled(False)
      self.saveBtn.setEnabled(False)
      self.imgs=[]
      self.label.setText('0/4')
      cv.destroyWindow(' ')
  ```
</details>

### 저장 기능
- `QFileDialog`으로 파일 저장 이름 선택 후 이미지 저장
<img src="https://github.com/irrso/computer-vision-4-snapshots-pc.ver/assets/105829324/0d502cfd-f212-41c1-ada2-8919848e8954" width="35%"/>

 <details>
    <summary> <img src="https://img.shields.io/badge/saveFunction-3776AB.svg?style=flat-square"/> </summary>
   
```Python
  def savcloseFunction(self):
      # 사진 저장
      fname = QFileDialog.getSaveFileName(self, '파일 저장', './', 'Image files (*.jpeg)')
      cv.imwrite(fname[0], self.stack)
  ```
</details>
